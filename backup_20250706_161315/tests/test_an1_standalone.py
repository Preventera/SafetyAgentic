# Test AN1 Standalone - Analyste √âcarts SafetyAgentic
# ===================================================
# Version autonome sans imports externes

import asyncio
import numpy as np
from datetime import datetime
import logging

# Configuration logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SafetyAgentic.AN1")

class AN1AnalysteEcarts:
    """
    Agent AN1 - Analyste des √âcarts Culture S√©curit√©
    Version standalone pour test
    """
    
    def __init__(self):
        """Initialisation Agent AN1"""
        self.agent_id = "AN1"
        self.agent_name = "Analyste √âcarts"
        self.version = "1.0.0"
        
        # Mod√®les HSE int√©gr√©s
        self.hse_models = {
            "hfacs_l1": "√âchecs organisationnels",
            "hfacs_l2": "Supervision inad√©quate", 
            "hfacs_l3": "Actes/conditions pr√©curseurs",
            "hfacs_l4": "Actes/conditions dangereux",
            "swiss_cheese": "D√©faillances barri√®res",
            "srk": "Niveaux comportement (Skill-Rule-Knowledge)",
            "reason": "Erreurs actives vs latentes",
            "bow_tie": "Analyse barri√®res pr√©ventives/protectives"
        }
        
        # Seuils d'√©carts critiques
        self.ecart_thresholds = {
            "faible": 10,      # √âcart < 10% = acceptable
            "modere": 25,      # √âcart 10-25% = √† surveiller
            "eleve": 50,       # √âcart 25-50% = critique
            "critique": 100    # √âcart > 50% = zone aveugle majeure
        }
        
        logger.info(f"ü§ñ Agent {self.agent_id} ({self.agent_name}) initialis√©")
        print(f"ü§ñ Agent {self.agent_id} ({self.agent_name}) initialis√©")
    
    async def process(self, data_a1, data_a2, context=None):
        """Traitement principal: analyser √©carts A1 vs A2"""
        start_time = datetime.now()
        logger.info("üîÑ D√©marrage traitement Agent AN1")
        
        try:
            # 1. Validation donn√©es d'entr√©e
            self._validate_input_data(data_a1, data_a2)
            logger.info("‚úÖ Validation des donn√©es d'entr√©e r√©ussie")
            
            # 2. Calcul √©carts variables culture SST
            ecarts_variables = self._calculate_culture_gaps(data_a1, data_a2)
            
            # 3. Application des mod√®les HSE
            analysis_hse = self._apply_hse_models(ecarts_variables, context)
            
            # 4. Identification zones aveugles
            zones_aveugles = self._identify_blind_spots(ecarts_variables)
            
            # 5. Calcul scores r√©alisme culturel
            realisme_scores = self._calculate_realism_scores(data_a1, data_a2)
            
            # 6. G√©n√©ration recommandations cibl√©es
            recommendations = self._generate_targeted_recommendations(
                ecarts_variables, zones_aveugles, analysis_hse
            )
            
            # 7. Calcul m√©triques performance
            performance_time = (datetime.now() - start_time).total_seconds()
            confidence_score = self._calculate_confidence_score(ecarts_variables)
            
            logger.info(f"üìä Performance AN1: {performance_time:.2f}s, confidence: {confidence_score:.2f}")
            
            # 8. Construction r√©sultat final
            result = {
                "agent_info": {
                    "agent_id": self.agent_id,
                    "agent_name": self.agent_name,
                    "version": self.version,
                    "timestamp": datetime.now().isoformat(),
                    "performance_time": performance_time,
                    "confidence_score": confidence_score
                },
                "ecarts_analysis": {
                    "ecarts_variables": ecarts_variables,
                    "zones_aveugles": zones_aveugles,
                    "realisme_scores": realisme_scores,
                    "nombre_ecarts_critiques": len([e for e in ecarts_variables.values() if e.get("niveau") == "critique"])
                },
                "hse_models_analysis": analysis_hse,
                "recommendations": recommendations,
                "summary": {
                    "ecart_moyen": np.mean([e.get("pourcentage", 0) for e in ecarts_variables.values()]),
                    "variables_critiques": len(zones_aveugles),
                    "actions_recommandees": len(recommendations),
                    "priorite_intervention": self._determine_intervention_priority(zones_aveugles)
                }
            }
            
            logger.info(f"‚úÖ Agent AN1 termin√© - Score confiance: {confidence_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur Agent AN1: {str(e)}")
            return {"error": str(e), "agent_id": self.agent_id}
    
    def _validate_input_data(self, data_a1, data_a2):
        """Validation des donn√©es A1 et A2"""
        if not data_a1 or not data_a2:
            raise ValueError("Donn√©es A1 ou A2 manquantes")
        
        required_a1 = ["variables_culture_sst"]
        required_a2 = ["variables_culture_terrain"]
        
        for field in required_a1:
            if field not in data_a1:
                raise ValueError(f"Champ manquant A1: {field}")
                
        for field in required_a2:
            if field not in data_a2:
                raise ValueError(f"Champ manquant A2: {field}")
    
    def _calculate_culture_gaps(self, data_a1, data_a2):
        """Calcul √©carts entre variables culture A1 vs A2"""
        ecarts = {}
        
        vars_a1 = data_a1.get("variables_culture_sst", {})
        vars_a2 = data_a2.get("variables_culture_terrain", {})
        
        for variable in set(vars_a1.keys()).intersection(set(vars_a2.keys())):
            score_a1 = vars_a1[variable].get("score", 0)
            score_a2 = vars_a2[variable].get("score", 0)
            
            # Calcul √©cart relatif
            if score_a1 > 0:
                ecart_pct = abs(score_a1 - score_a2) / score_a1 * 100
            else:
                ecart_pct = abs(score_a2) * 10
            
            # Classification niveau √©cart
            if ecart_pct < self.ecart_thresholds["faible"]:
                niveau = "faible"
            elif ecart_pct < self.ecart_thresholds["modere"]:
                niveau = "modere"
            elif ecart_pct < self.ecart_thresholds["eleve"]:
                niveau = "eleve"
            else:
                niveau = "critique"
            
            ecarts[variable] = {
                "score_autoeval": score_a1,
                "score_terrain": score_a2,
                "ecart_absolu": abs(score_a1 - score_a2),
                "pourcentage": ecart_pct,
                "niveau": niveau,
                "direction": "surestimation" if score_a1 > score_a2 else "sous_estimation",
                "variable_source_a1": vars_a1[variable].get("source", "unknown"),
                "variable_source_a2": vars_a2[variable].get("source", "unknown")
            }
        
        return ecarts
    
    def _apply_hse_models(self, ecarts_variables, context=None):
        """Application des mod√®les HSE sur les √©carts"""
        hse_analysis = {}
        
        for model_code, model_name in self.hse_models.items():
            if model_code.startswith("hfacs"):
                analysis = self._apply_hfacs_model(model_code, ecarts_variables)
            elif model_code == "swiss_cheese":
                analysis = self._apply_swiss_cheese_model(ecarts_variables)
            elif model_code == "srk":
                analysis = self._apply_srk_model(ecarts_variables)
            else:
                analysis = self._apply_generic_hse_model(model_code, ecarts_variables)
            
            hse_analysis[model_code] = {
                "model_name": model_name,
                "analysis": analysis,
                "variables_impliquees": len([v for v in ecarts_variables.keys() 
                                           if ecarts_variables[v]["niveau"] in ["eleve", "critique"]]),
                "score_applicabilite": self._calculate_model_applicability(model_code, ecarts_variables)
            }
        
        return hse_analysis
    
    def _apply_hfacs_model(self, level, ecarts):
        """Application mod√®le HFACS selon niveau"""
        hfacs_mapping = {
            "hfacs_l1": ["leadership_sst", "politique_securite"],
            "hfacs_l2": ["supervision_directe", "formation_securite"],
            "hfacs_l3": ["usage_epi", "respect_procedures"],
            "hfacs_l4": ["comportements_risque", "communication_risques"]
        }
        
        variables_concernees = hfacs_mapping.get(level, [])
        ecarts_niveau = {v: ecarts[v] for v in variables_concernees if v in ecarts}
        
        score_defaillance = np.mean([e["pourcentage"] for e in ecarts_niveau.values()]) if ecarts_niveau else 0
        
        return {
            "niveau_hfacs": level,
            "variables_analysees": len(ecarts_niveau),
            "ecarts_critiques": len([e for e in ecarts_niveau.values() if e["niveau"] == "critique"]),
            "score_defaillance": score_defaillance,
            "interpretation": self._interpret_hfacs_level(level, score_defaillance)
        }
    
    def _interpret_hfacs_level(self, level, score):
        """Interpr√©tation du score HFACS par niveau"""
        interpretations = {
            "hfacs_l1": f"D√©faillances organisationnelles: {score:.1f}% - Engagement leadership",
            "hfacs_l2": f"Supervision inad√©quate: {score:.1f}% - Encadrement terrain", 
            "hfacs_l3": f"Conditions pr√©curseurs: {score:.1f}% - Pr√©vention incidents",
            "hfacs_l4": f"Actes dangereux: {score:.1f}% - Comportements risque"
        }
        return interpretations.get(level, f"Analyse {level}: {score:.1f}%")
    
    def _apply_swiss_cheese_model(self, ecarts):
        """Application mod√®le Swiss Cheese"""
        barrieres = {
            "organisationnelles": ["leadership_sst", "formation_securite"],
            "supervision": ["supervision_directe", "communication_risques"],
            "individuelles": ["usage_epi", "respect_procedures"]
        }
        
        defaillances = {}
        for barriere_type, variables in barrieres.items():
            ecarts_barriere = {v: ecarts[v] for v in variables if v in ecarts}
            if ecarts_barriere:
                defaillance_score = np.mean([e["pourcentage"] for e in ecarts_barriere.values()])
                defaillances[barriere_type] = {
                    "score_defaillance": defaillance_score,
                    "variables_impliquees": list(ecarts_barriere.keys()),
                    "niveau_risque": "high" if defaillance_score > 30 else "medium" if defaillance_score > 15 else "low"
                }
        
        return {
            "defaillances_barrieres": defaillances,
            "risque_global": max([d["score_defaillance"] for d in defaillances.values()]) if defaillances else 0,
            "barrieres_critiques": [k for k, v in defaillances.items() if v["niveau_risque"] == "high"]
        }
    
    def _apply_srk_model(self, ecarts):
        """Application mod√®le SRK"""
        srk_mapping = {
            "skill": ["usage_epi", "competences_techniques"],
            "rule": ["respect_procedures", "formation_securite"],
            "knowledge": ["communication_risques", "supervision_directe"]
        }
        
        srk_analysis = {}
        for niveau, variables in srk_mapping.items():
            ecarts_niveau = {v: ecarts[v] for v in variables if v in ecarts}
            if ecarts_niveau:
                score_ecart = np.mean([e["pourcentage"] for e in ecarts_niveau.values()])
                srk_analysis[niveau] = {
                    "score_ecart": score_ecart,
                    "variables_count": len(ecarts_niveau),
                    "niveau_defaillance": "critique" if score_ecart > 40 else "eleve" if score_ecart > 20 else "faible"
                }
        
        return srk_analysis
    
    def _apply_generic_hse_model(self, model_code, ecarts):
        """Analyse g√©n√©rique pour autres mod√®les HSE"""
        return {
            "model_code": model_code,
            "variables_analysees": len(ecarts),
            "score_global": np.mean([e["pourcentage"] for e in ecarts.values()]) if ecarts else 0
        }
    
    def _identify_blind_spots(self, ecarts_variables):
        """Identification zones aveugles culture s√©curit√©"""
        zones_aveugles = []
        
        for variable, ecart_data in ecarts_variables.items():
            if ecart_data["niveau"] in ["eleve", "critique"]:
                zone_aveugle = {
                    "variable": variable,
                    "type_ecart": ecart_data["direction"],
                    "pourcentage_ecart": ecart_data["pourcentage"],
                    "niveau_critique": ecart_data["niveau"],
                    "score_autoeval": ecart_data["score_autoeval"],
                    "score_terrain": ecart_data["score_terrain"],
                    "explication": self._explain_blind_spot(variable, ecart_data),
                    "impact_potentiel": self._assess_blind_spot_impact(variable, ecart_data)
                }
                zones_aveugles.append(zone_aveugle)
        
        zones_aveugles.sort(key=lambda x: x["pourcentage_ecart"], reverse=True)
        return zones_aveugles
    
    def _explain_blind_spot(self, variable, ecart_data):
        """Explication textuelle de la zone aveugle"""
        direction = ecart_data["direction"]
        pct = ecart_data["pourcentage"]
        
        if direction == "surestimation":
            return f"Surestimation de {pct:.1f}% sur {variable}. L'√©quipe pense mieux performer qu'en r√©alit√©."
        else:
            return f"Sous-estimation de {pct:.1f}% sur {variable}. Performance terrain sup√©rieure aux perceptions."
    
    def _assess_blind_spot_impact(self, variable, ecart_data):
        """√âvaluation impact potentiel zone aveugle"""
        variable_criticality = {
            "usage_epi": "high",
            "respect_procedures": "high", 
            "supervision_directe": "high",
            "formation_securite": "medium",
            "communication_risques": "medium"
        }
        
        criticality = variable_criticality.get(variable, "medium")
        ecart_level = ecart_data["niveau"]
        
        if criticality == "high" and ecart_level == "critique":
            return "CRITIQUE - Risque incident majeur"
        elif criticality == "high" or ecart_level == "critique":
            return "√âLEV√â - Intervention urgente requise"
        else:
            return "MOD√âR√â - Surveillance renforc√©e"
    
    def _calculate_realism_scores(self, data_a1, data_a2):
        """Calcul scores r√©alisme culturel"""
        scores_a1 = data_a1.get("scores_autoeval", {})
        observations_a2 = data_a2.get("observations", {})
        
        score_global_a1 = scores_a1.get("score_global", 70)
        score_comportement_a2 = observations_a2.get("score_comportement", 50)
        
        realisme_global = max(0, 100 - abs(score_global_a1 - score_comportement_a2))
        
        return {
            "realisme_global": realisme_global,
            "fiabilite_autoeval": min(100, realisme_global + 10),
            "coherence_perception": realisme_global,
            "niveau_autocritique": "√©lev√©" if realisme_global > 80 else "moyen" if realisme_global > 60 else "faible"
        }
    
    def _generate_targeted_recommendations(self, ecarts, zones_aveugles, hse_analysis):
        """G√©n√©ration recommandations cibl√©es"""
        recommendations = []
        
        # Recommandations par zone aveugle
        for zone in zones_aveugles[:5]:
            rec = {
                "type": "zone_aveugle",
                "priorite": "URGENTE" if zone["niveau_critique"] == "critique" else "√âLEV√âE",
                "variable_cible": zone["variable"],
                "action": f"Corriger √©cart {zone['type_ecart']} de {zone['pourcentage_ecart']:.1f}% sur {zone['variable']}",
                "methode": self._recommend_correction_method(zone["variable"], zone["type_ecart"]),
                "timeline": "2-4 semaines" if zone["niveau_critique"] == "critique" else "1-2 mois",
                "ressources_requises": self._estimate_resources(zone["variable"], zone["pourcentage_ecart"])
            }
            recommendations.append(rec)
        
        # Recommandations g√©n√©rales
        if len(zones_aveugles) > 2:
            recommendations.append({
                "type": "global",
                "priorite": "√âLEV√âE", 
                "action": "Programme am√©lioration culture s√©curit√© globale",
                "methode": "Formation management + observations terrain syst√©matiques",
                "timeline": "3-6 mois"
            })
        
        return recommendations
    
    def _recommend_correction_method(self, variable, direction):
        """Recommandation m√©thode correction"""
        methods = {
            "usage_epi": {
                "surestimation": "Observations terrain cibl√©es + formations pratiques",
                "sous_estimation": "Sensibilisation performance + reconnaissance efforts"
            },
            "supervision_directe": {
                "surestimation": "Formation superviseurs + audits conformit√©",
                "sous_estimation": "Valorisation encadrement + outils supervision"
            },
            "respect_procedures": {
                "surestimation": "Audit conformit√© + coaching terrain",
                "sous_estimation": "Communication succ√®s + reconnaissance"
            }
        }
        
        return methods.get(variable, {}).get(direction, "Formation cibl√©e + suivi renforc√©")
    
    def _estimate_resources(self, variable, ecart_pct):
        """Estimation ressources requises"""
        if ecart_pct > 50:
            return "Ressources importantes - Formation compl√®te √©quipe"
        elif ecart_pct > 25:
            return "Ressources mod√©r√©es - Formation superviseurs"
        else:
            return "Ressources limit√©es - Sensibilisation cibl√©e"
    
    def _calculate_model_applicability(self, model_code, ecarts):
        """Calcul score applicabilit√© mod√®le"""
        variables_critiques = len([e for e in ecarts.values() if e["niveau"] in ["eleve", "critique"]])
        total_variables = len(ecarts) if ecarts else 1
        
        base_score = (variables_critiques / total_variables) * 100
        return min(95, max(20, base_score + 20))
    
    def _calculate_confidence_score(self, ecarts_variables):
        """Calcul score confiance global"""
        if not ecarts_variables:
            return 0.5
        
        coherence = np.mean([1 - min(1, e["pourcentage"] / 100) for e in ecarts_variables.values()])
        completude = min(1.0, len(ecarts_variables) / 8)
        
        return max(0.3, min(0.95, (coherence * 0.7) + (completude * 0.3)))
    
    def _determine_intervention_priority(self, zones_aveugles):
        """D√©termination priorit√© intervention"""
        if not zones_aveugles:
            return "FAIBLE"
        
        critiques = len([z for z in zones_aveugles if z["niveau_critique"] == "critique"])
        eleves = len([z for z in zones_aveugles if z["niveau_critique"] == "eleve"])
        
        if critiques >= 3:
            return "URGENTE"
        elif critiques >= 1 or eleves >= 5:
            return "√âLEV√âE"
        elif eleves >= 2:
            return "MOYENNE"
        else:
            return "FAIBLE"


async def test_agent_an1_standalone():
    """Test standalone Agent AN1"""
    
    print("üß™ TEST AGENT AN1 - ANALYSTE √âCARTS")
    print("=" * 40)
    print("üéØ Focus: Analyse √©carts A1 (auto√©val) vs A2 (terrain)")
    print("üî¨ Mod√®les HSE: HFACS, Swiss Cheese, SRK, Bow-Tie")
    print("‚ö†Ô∏è Zones aveugles: Identification automatique")
    
    # Donn√©es A1 (auto√©valuations) - Scores optimistes
    print("\nüìä DONN√âES A1 (AUTO√âVALUATIONS):")
    data_a1 = {
        "variables_culture_sst": {
            "usage_epi": {"score": 8.5, "source": "questionnaire", "confiance": 0.9},
            "respect_procedures": {"score": 7.8, "source": "questionnaire", "confiance": 0.8},
            "formation_securite": {"score": 7.2, "source": "questionnaire", "confiance": 0.8},
            "supervision_directe": {"score": 7.5, "source": "questionnaire", "confiance": 0.7},
            "communication_risques": {"score": 6.8, "source": "questionnaire", "confiance": 0.8},
            "leadership_sst": {"score": 7.0, "source": "questionnaire", "confiance": 0.7}
        },
        "scores_autoeval": {
            "score_global": 74,
            "fiabilite": 0.8,
            "biais_detectes": ["surconfiance", "desirabilite_sociale"]
        }
    }
    
    for var, data in data_a1["variables_culture_sst"].items():
        print(f"  ‚Ä¢ {var}: {data['score']}/10 (confiance: {data['confiance']})")
    
    # Donn√©es A2 (observations terrain) - R√©alit√© moins optimiste
    print("\nüîç DONN√âES A2 (OBSERVATIONS TERRAIN):")
    data_a2 = {
        "variables_culture_terrain": {
            "usage_epi": {"score": 4.8, "source": "observation_epi", "observations": 15},
            "respect_procedures": {"score": 5.2, "source": "procedure_compliance", "observations": 12},
            "formation_securite": {"score": 7.0, "source": "behavioral_analysis", "observations": 8},
            "supervision_directe": {"score": 3.5, "source": "hazard_detection", "observations": 10},
            "communication_risques": {"score": 5.5, "source": "behavioral_analysis", "observations": 6},
            "leadership_sst": {"score": 4.2, "source": "hazard_detection", "observations": 5}
        },
        "observations": {
            "score_comportement": 48,
            "dangers_detectes": 3,
            "epi_analyses": 15,
            "conformite_procedures": 45.0
        }
    }
    
    for var, data in data_a2["variables_culture_terrain"].items():
        print(f"  ‚Ä¢ {var}: {data['score']}/10 (observations: {data['observations']})")
    
    # Contexte
    context = {
        "secteur_scian": "CONSTRUCTION",
        "type_incident": "CHUTE_HAUTEUR", 
        "gravite": "MAJEUR"
    }
    
    print(f"\nüèóÔ∏è CONTEXTE: {context['secteur_scian']} - {context['type_incident']}")
    
    print("\nü§ñ Initialisation Agent AN1...")
    agent_an1 = AN1AnalysteEcarts()
    
    print("\nüîÑ ANALYSE √âCARTS A1 vs A2:")
    print("=" * 35)
    
    result = await agent_an1.process(data_a1, data_a2, context)
    
    if "error" in result:
        print(f"‚ùå Erreur: {result['error']}")
        return
    
    # R√©sultats
    print(f"‚úÖ Score confiance: {result['agent_info']['confidence_score']:.3f}")
    print(f"üìä Variables analys√©es: {len(result['ecarts_analysis']['ecarts_variables'])}")
    print(f"‚ö†Ô∏è √âcarts critiques: {result['ecarts_analysis']['nombre_ecarts_critiques']}")
    print(f"üî¨ Mod√®les HSE: {len(result['hse_models_analysis'])}")
    print(f"üí° Recommandations: {len(result['recommendations'])}")
    
    # √âcarts d√©taill√©s
    print("\nüéØ √âCARTS D√âTECT√âS PAR VARIABLE:")
    for var, ecart in result['ecarts_analysis']['ecarts_variables'].items():
        autoeval = ecart['score_autoeval']
        terrain = ecart['score_terrain']
        pct = ecart['pourcentage']
        niveau = ecart['niveau']
        direction = ecart['direction']
        
        icon = "üö®" if niveau == "critique" else "‚ö†Ô∏è" if niveau == "eleve" else "üìä"
        print(f"  {icon} {var}:")
        print(f"     Auto√©val: {autoeval}/10 | Terrain: {terrain}/10")
        print(f"     √âcart: {pct:.1f}% ({niveau}) - {direction}")
    
    # Zones aveugles
    print("\n‚ö†Ô∏è ZONES AVEUGLES IDENTIFI√âES:")
    zones = result['ecarts_analysis']['zones_aveugles']
    if zones:
        for i, zone in enumerate(zones[:3], 1):
            print(f"  {i}. {zone['variable']} ({zone['niveau_critique'].upper()})")
            print(f"     ‚Üí √âcart: {zone['pourcentage_ecart']:.1f}% - {zone['type_ecart']}")
            print(f"     ‚Üí Impact: {zone['impact_potentiel']}")
            print(f"     ‚Üí {zone['explication']}")
    else:
        print("  ‚úÖ Aucune zone aveugle critique d√©tect√©e")
    
    # Mod√®les HSE
    print("\nüî¨ ANALYSE MOD√àLES HSE:")
    for model_code, analysis in result['hse_models_analysis'].items():
        print(f"  üéØ {analysis['model_name']}")
        print(f"     Applicabilit√©: {analysis['score_applicabilite']:.0f}%")
        
        if 'interpretation' in analysis['analysis']:
            print(f"     ‚Üí {analysis['analysis']['interpretation']}")
        elif 'barrieres_critiques' in analysis['analysis']:
            barrieres = analysis['analysis']['barrieres_critiques']
            if barrieres:
                print(f"     ‚Üí Barri√®res critiques: {', '.join(barrieres)}")
    
    # Recommandations
    print("\nüí° RECOMMANDATIONS PRIORITAIRES:")
    for i, rec in enumerate(result['recommendations'][:4], 1):
        priorite = rec['priorite']
        icon = "üö®" if priorite == "URGENTE" else "‚ö†Ô∏è" if priorite == "√âLEV√âE" else "üìã"
        print(f"  {i}. {icon} {priorite}")
        print(f"     Action: {rec['action']}")
        if 'methode' in rec:
            print(f"     M√©thode: {rec['methode']}")
        if 'timeline' in rec:
            print(f"     Timeline: {rec['timeline']}")
    
    # R√©sum√©
    print("\n" + "=" * 50)
    print("üìã R√âSUM√â ANALYSE √âCARTS AN1")
    print("=" * 50)
    summary = result['summary']
    print(f"‚úÖ Confiance: {result['agent_info']['confidence_score']:.1%}")
    print(f"üìä √âcart moyen: {summary['ecart_moyen']:.1f}%")
    print(f"‚ö†Ô∏è Variables critiques: {summary['variables_critiques']}")
    print(f"üéØ Actions recommand√©es: {summary['actions_recommandees']}")
    print(f"üö® Priorit√©: {summary['priorite_intervention']}")
    
    # Interpr√©tation
    if summary['priorite_intervention'] == 'URGENTE':
        print("\nüö® ALERTE: √âcarts critiques - Intervention imm√©diate requise")
        print("   ‚Üí Risque incident majeur si non corrig√© rapidement")
    elif summary['priorite_intervention'] == '√âLEV√âE':
        print("\n‚ö†Ô∏è ATTENTION: √âcarts significatifs - Action rapide recommand√©e")
        print("   ‚Üí Planifier interventions dans les 2-4 semaines")
    else:
        print("\n‚úÖ SITUATION: √âcarts g√©rables - Surveillance renforc√©e")
        print("   ‚Üí Maintenir vigilance et am√©lioration continue")
    
    print(f"\nüéâ TEST AGENT AN1 TERMIN√â!")
    print(f"‚è±Ô∏è Performance: {result['agent_info']['performance_time']:.3f}s")
    print(f"üéØ Agent AN1 pr√™t pour orchestration SafetyAgentic")
    
    return result

if __name__ == "__main__":
    asyncio.run(test_agent_an1_standalone())