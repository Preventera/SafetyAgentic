"""
STORM Launcher - Syst√®me de recherche automatis√©e pour optimiser Safety Agentique
Int√©gration des 100 sujets de recherche HSE pour enrichir le corpus d'analyse
"""

import asyncio
import os
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import logging

# Configuration logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class StormLauncher:
    """Gestionnaire principal des recherches STORM pour Safety Agentique"""
    
    def __init__(self):
        self.base_path = Path("C:/Users/Mario/Documents/PROJECTS_NEW/SafeGraph")
        self.storm_knowledge_path = self.base_path / "data" / "storm_knowledge"
        self.config_path = self.base_path / "config"
        
        # Cr√©er r√©pertoires si inexistants
        self.storm_knowledge_path.mkdir(parents=True, exist_ok=True)
        self.config_path.mkdir(parents=True, exist_ok=True)
        
        # Categories STORM Safety Agentique
        self.safety_topics = {
            "Leadership_HSE": [
                "transformational_safety_leadership", "management_commitment_hse", 
                "supervisor_engagement_prevention", "safety_leadership_development",
                "decision_making_risk_based", "authority_accountability_safety",
                "role_modeling_behavior", "visionary_safety_leadership",
                "collaborative_safety_management", "authentic_leadership_hse"
            ],
            "Communication_Prevention": [
                "safety_communication_effectiveness", "incident_reporting_culture",
                "feedback_loops_prevention", "multilingual_safety_communication",
                "crisis_communication_hse", "stakeholder_safety_engagement",
                "transparent_risk_communication", "safety_dialogue_quality",
                "non_violent_safety_communication", "listening_safety_concerns"
            ],
            "Formation_Competences": [
                "competency_based_safety_training", "skill_assessment_hse",
                "learning_transfer_workplace", "simulation_safety_training",
                "microlearning_prevention", "peer_safety_learning",
                "mentoring_safety_programs", "knowledge_retention_hse",
                "training_evaluation_roi", "adaptive_safety_learning"
            ],
            "Mesure_Analytics": [
                "leading_safety_indicators", "lagging_safety_metrics",
                "predictive_safety_analytics", "safety_culture_measurement",
                "incident_analysis_techniques", "safety_data_visualization",
                "performance_safety_dashboards", "trend_analysis_hse",
                "benchmarking_safety_performance", "real_time_safety_monitoring"
            ],
            "Engagement_Comportement": [
                "employee_safety_participation", "behavior_based_safety",
                "safety_recognition_programs", "employee_safety_empowerment",
                "safety_suggestion_systems", "safety_committee_effectiveness",
                "peer_safety_support", "safety_motivation_theories",
                "engagement_safety_surveys", "safety_retention_strategies"
            ],
            "Gestion_Risques": [
                "hazard_identification_systematic", "quantitative_risk_assessment",
                "risk_control_hierarchy", "dynamic_risk_assessment",
                "job_safety_analysis_jsa", "bow_tie_risk_analysis",
                "fault_tree_safety_analysis", "human_factors_safety",
                "system_safety_engineering", "risk_prioritization_matrix"
            ],
            "Conformite_Standards": [
                "regulatory_compliance_hse", "safety_audit_systems",
                "documentation_safety_management", "safety_procedures_sop",
                "permit_safety_systems", "inspection_safety_protocols",
                "legal_safety_requirements", "iso45001_implementation",
                "gap_analysis_safety", "compliance_safety_monitoring"
            ],
            "Innovation_Technologie": [
                "iot_safety_applications", "ai_safety_applications",
                "wearable_safety_technology", "mobile_safety_apps",
                "automation_safety_systems", "digital_safety_transformation",
                "safety_technology_adoption", "process_safety_improvement",
                "best_practices_safety_sharing", "innovation_safety_culture"
            ],
            "Culture_Organisationnelle": [
                "psychological_safety_workplace", "safety_values_alignment",
                "safety_belief_systems", "organizational_safety_climate",
                "trust_building_safety", "safety_cultural_change",
                "diversity_inclusion_safety", "work_life_balance_safety",
                "stress_management_workplace", "resilience_building_safety"
            ],
            "Performance_Amelioration": [
                "safety_outcome_measurement", "continuous_safety_improvement",
                "lean_safety_management", "six_sigma_safety",
                "kaizen_safety_events", "lessons_learned_safety",
                "post_incident_safety_analysis", "safety_improvement_tracking",
                "roi_safety_measurement", "excellence_safety_programs"
            ]
        }
        
        # Sources prioritaires pour recherche HSE
        self.safety_sources = {
            "academic": [
                "Safety Science Journal", "Accident Analysis & Prevention",
                "Journal of Safety Research", "International Journal of Occupational Safety",
                "Applied Ergonomics", "Human Factors"
            ],
            "institutional": [
                "INRS France", "NIOSH CDC", "HSE UK",
                "CNESST Quebec", "IRSST", "European Agency Safety Health"
            ],
            "standards": [
                "ISO 45001", "ISO 14001", "OHSAS 18001",
                "ILO Safety Standards", "ANSI Z10", "CSA Z1000"
            ],
            "sectorial": [
                "Construction Safety Research", "Manufacturing Safety Studies",
                "Healthcare Safety Research", "Transport Safety Analysis",
                "Mining Safety Publications"
            ]
        }

    def get_priority_topics_for_safety_agentique(self) -> List[Dict]:
        """Retourne les sujets prioritaires pour enrichir Safety Agentique"""
        
        priority_mapping = {
            # Priorit√© CRITIQUE - Impact direct analyses Safety Agentique
            1: [
                "behavior_based_safety", "incident_analysis_techniques", 
                "leading_safety_indicators", "safety_culture_measurement",
                "hazard_identification_systematic", "predictive_safety_analytics"
            ],
            # Priorit√© √âLEV√âE - Enrichissement recommandations
            2: [
                "competency_based_safety_training", "safety_communication_effectiveness",
                "management_commitment_hse", "employee_safety_participation",
                "continuous_safety_improvement", "psychological_safety_workplace"
            ],
            # Priorit√© MOYENNE - Contexte sectoriel SCIAN
            3: [
                "regulatory_compliance_hse", "job_safety_analysis_jsa",
                "safety_technology_adoption", "peer_safety_learning",
                "roi_safety_measurement", "organizational_safety_climate"
            ]
        }
        
        priority_topics = []
        for priority_level, topics in priority_mapping.items():
            for topic in topics:
                # Trouver la cat√©gorie du sujet
                category = None
                for cat, cat_topics in self.safety_topics.items():
                    if topic in cat_topics:
                        category = cat
                        break
                
                priority_topics.append({
                    "topic": topic,
                    "category": category,
                    "priority": priority_level,
                    "safety_agentique_impact": self._get_impact_description(topic)
                })
        
        return sorted(priority_topics, key=lambda x: x["priority"])

    def _get_impact_description(self, topic: str) -> str:
        """Description impact sur Safety Agentique"""
        impact_map = {
            "behavior_based_safety": "Enrichit agents A1-A3 collecte comportements observables",
            "incident_analysis_techniques": "Am√©liore agents AN1-AN5 d√©tection patterns incidents",
            "leading_safety_indicators": "Optimise agents AN6-AN10 pr√©diction proactive",
            "safety_culture_measurement": "Renforce scoring culture s√©curit√© global",
            "hazard_identification_systematic": "Enrichit base connaissances identification risques",
            "predictive_safety_analytics": "Am√©liore mod√®les pr√©dictifs sectoriels SCIAN",
            "competency_based_safety_training": "Optimise agents R1-R5 recommandations formation",
            "safety_communication_effectiveness": "Enrichit agents R6-R10 communication plans",
            "management_commitment_hse": "Am√©liore agents SC leadership sectoriels",
            "employee_safety_participation": "Optimise mesure engagement collaborateurs",
            "continuous_safety_improvement": "Enrichit boucles feedback am√©lioration",
            "psychological_safety_workplace": "Am√©liore √©valuation climat organisationnel"
        }
        return impact_map.get(topic, "Enrichissement corpus g√©n√©ral Safety Agentique")

    async def launch_storm_research(self, topics: List[str] = None, max_concurrent: int = 3):
        """Lance recherches STORM pour topics sp√©cifi√©s"""
        
        if not topics:
            priority_topics = self.get_priority_topics_for_safety_agentique()
            topics = [t["topic"] for t in priority_topics[:10]]  # Top 10 prioritaires
        
        logger.info(f"üåü Lancement recherche STORM pour {len(topics)} sujets Safety Agentique")
        
        # Semaphore pour limiter recherches concurrentes
        semaphore = asyncio.Semaphore(max_concurrent)
        
        # Lancer recherches en parall√®le
        tasks = [self._research_topic(semaphore, topic) for topic in topics]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Compiler r√©sultats
        successful_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå Erreur recherche {topics[i]}: {result}")
            else:
                successful_results.append(result)
                logger.info(f"‚úÖ Recherche termin√©e: {result['topic']}")
        
        # Sauvegarder corpus enrichi
        await self._save_enriched_corpus(successful_results)
        
        return successful_results

    async def _research_topic(self, semaphore: asyncio.Semaphore, topic: str) -> Dict:
        """Recherche approfondie pour un sujet sp√©cifique"""
        
        async with semaphore:
            logger.info(f"üîç D√©but recherche: {topic}")
            
            # Simulation recherche (√† remplacer par vraie recherche)
            await asyncio.sleep(2)  # Simule temps recherche
            
            # Structure r√©sultat recherche
            research_result = {
                "topic": topic,
                "timestamp": datetime.now().isoformat(),
                "sources_found": self._simulate_sources(topic),
                "key_findings": self._simulate_findings(topic),
                "recommendations": self._simulate_recommendations(topic),
                "citations": self._simulate_citations(topic),
                "safety_agentique_integration": self._get_integration_points(topic)
            }
            
            return research_result

    def _simulate_sources(self, topic: str) -> List[Dict]:
        """Simule sources trouv√©es (√† remplacer par vraie recherche)"""
        return [
            {
                "title": f"Recent advances in {topic.replace('_', ' ')}",
                "authors": ["Smith, J.", "Johnson, M."],
                "journal": "Safety Science Journal",
                "year": 2024,
                "relevance_score": 0.92,
                "abstract": f"Comprehensive review of {topic} methodologies and applications..."
            },
            {
                "title": f"Industry best practices for {topic.replace('_', ' ')}",
                "source": "INRS",
                "type": "technical_guide",
                "year": 2023,
                "relevance_score": 0.88,
                "key_points": [f"Implementation strategies for {topic}", "Sector-specific applications"]
            }
        ]

    def _simulate_findings(self, topic: str) -> List[str]:
        """Simule conclusions cl√©s recherche"""
        findings_map = {
            "behavior_based_safety": [
                "Programs focusing on observation increase safety performance by 35%",
                "Peer feedback mechanisms more effective than supervisor-only feedback",
                "Technology-assisted observation shows 50% better compliance tracking"
            ],
            "incident_analysis_techniques": [
                "Root cause analysis combined with STAMP methodology increases accuracy by 60%",
                "Machine learning pattern detection identifies 23% more contributing factors",
                "Cross-industry analysis reveals common organizational factors"
            ],
            "safety_culture_measurement": [
                "Multi-dimensional scales more predictive than single-factor assessments",
                "Real-time pulse surveys outperform annual culture surveys",
                "Integration with behavioral data increases validity by 40%"
            ]
        }
        
        return findings_map.get(topic, [
            f"Key methodological advances in {topic}",
            f"Sector-specific applications of {topic}",
            f"Technology integration opportunities for {topic}"
        ])

    def _simulate_recommendations(self, topic: str) -> List[Dict]:
        """Simule recommandations pour Safety Agentique"""
        return [
            {
                "agent_category": "Collecte (A1-A10)",
                "recommendation": f"Int√©grer m√©thodologies {topic} dans questionnaires",
                "implementation": "Ajouter questions sp√©cifiques valid√©es par recherche",
                "expected_impact": "Am√©lioration pr√©cision collecte +25%"
            },
            {
                "agent_category": "Analyse (AN1-AN10)", 
                "recommendation": f"Utiliser algorithmes {topic} pour d√©tection patterns",
                "implementation": "Int√©grer mod√®les pr√©dictifs bas√©s litt√©rature",
                "expected_impact": "R√©duction faux positifs 30%"
            },
            {
                "agent_category": "Recommandations (R1-R10)",
                "recommendation": f"Personnaliser actions selon principes {topic}",
                "implementation": "Templates bas√©s meilleures pratiques sectorielles",
                "expected_impact": "Augmentation adoption recommandations +40%"
            }
        ]

    def _simulate_citations(self, topic: str) -> List[Dict]:
        """Simule citations acad√©miques"""
        return [
            {
                "citation": f"Heinrich, H.W. et al. (2024). Advanced {topic} in industrial settings. Safety Science, 45(3), 123-145.",
                "doi": "10.1016/j.ssci.2024.123456",
                "type": "peer_reviewed",
                "relevance": "high"
            },
            {
                "citation": f"INRS (2023). Guide pratique {topic}. ED 6789, Paris: INRS.",
                "type": "technical_standard",
                "language": "fr",
                "relevance": "high"
            }
        ]

    def _get_integration_points(self, topic: str) -> Dict:
        """Points d'int√©gration avec Safety Agentique"""
        return {
            "target_agents": self._get_target_agents(topic),
            "data_enrichment": f"Enrichissement base connaissances {topic}",
            "algorithm_enhancement": f"Am√©lioration algorithmes via recherche {topic}",
            "validation_criteria": f"Crit√®res validation bas√©s litt√©rature {topic}"
        }

    def _get_target_agents(self, topic: str) -> List[str]:
        """Agents Safety Agentique cibl√©s par le sujet"""
        agent_mapping = {
            "behavior_based_safety": ["A1", "A2", "A3", "AN1", "AN2"],
            "incident_analysis_techniques": ["AN3", "AN4", "AN5", "R1", "R2"],
            "safety_culture_measurement": ["A1", "AN1", "AN6", "S1", "S2"],
            "predictive_safety_analytics": ["AN6", "AN7", "AN8", "AN9", "AN10"]
        }
        return agent_mapping.get(topic, ["A1", "AN1", "R1"])

    async def _save_enriched_corpus(self, results: List[Dict]):
        """Sauvegarde corpus enrichi pour Safety Agentique"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        corpus_file = self.storm_knowledge_path / f"safety_agentique_corpus_{timestamp}.json"
        
        enriched_corpus = {
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "topics_researched": len(results),
                "total_sources": sum(len(r.get("sources_found", [])) for r in results),
                "safety_agentique_version": "1.0",
                "storm_engine_version": "2.0"
            },
            "research_results": results,
            "integration_summary": self._create_integration_summary(results)
        }
        
        with open(corpus_file, 'w', encoding='utf-8') as f:
            json.dump(enriched_corpus, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ Corpus enrichi sauvegard√©: {corpus_file}")
        
        # Cr√©er index pour Safety Agentique
        await self._create_agentique_index(enriched_corpus)

    def _create_integration_summary(self, results: List[Dict]) -> Dict:
        """Cr√©e r√©sum√© int√©gration pour Safety Agentique"""
        
        # Analyser impact par cat√©gorie d'agents
        agent_impacts = {}
        for result in results:
            for integration in result.get("recommendations", []):
                category = integration.get("agent_category", "Unknown")
                if category not in agent_impacts:
                    agent_impacts[category] = []
                agent_impacts[category].append({
                    "topic": result["topic"],
                    "impact": integration.get("expected_impact", ""),
                    "implementation": integration.get("implementation", "")
                })
        
        return {
            "agent_category_impacts": agent_impacts,
            "total_citations": sum(len(r.get("citations", [])) for r in results),
            "corpus_enhancement_areas": [
                "Behavior observation methodologies",
                "Predictive analytics algorithms", 
                "Risk assessment techniques",
                "Communication effectiveness measures",
                "Culture measurement instruments"
            ],
            "next_research_priorities": self._identify_research_gaps(results)
        }

    def _identify_research_gaps(self, results: List[Dict]) -> List[str]:
        """Identifie lacunes recherche pour prochaines it√©rations"""
        return [
            "Integration of IoT sensors with behavior observation",
            "Cross-cultural validity of safety culture instruments",
            "Real-time predictive models for incident prevention",
            "Sector-specific adaptation of safety communication",
            "ROI measurement of safety culture interventions"
        ]

    async def _create_agentique_index(self, corpus: Dict):
        """Cr√©e index optimis√© pour agents Safety Agentique"""
        
        index_file = self.storm_knowledge_path / "safety_agentique_index.json"
        
        # Organiser par cat√©gories d'agents
        agent_index = {
            "collecte_agents": {},
            "analyse_agents": {},
            "recommendation_agents": {},
            "sectoriel_agents": {}
        }
        
        for result in corpus["research_results"]:
            topic = result["topic"]
            
            # Mapper aux cat√©gories d'agents
            for recommendation in result.get("recommendations", []):
                category = recommendation.get("agent_category", "")
                
                if "Collecte" in category:
                    key = "collecte_agents"
                elif "Analyse" in category:
                    key = "analyse_agents"
                elif "Recommandations" in category:
                    key = "recommendation_agents"
                else:
                    key = "sectoriel_agents"
                
                if topic not in agent_index[key]:
                    agent_index[key][topic] = []
                
                agent_index[key][topic].append({
                    "findings": result.get("key_findings", []),
                    "citations": result.get("citations", []),
                    "implementation": recommendation.get("implementation", ""),
                    "expected_impact": recommendation.get("expected_impact", "")
                })
        
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(agent_index, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üìá Index Safety Agentique cr√©√©: {index_file}")

    def generate_launch_commands(self) -> Dict[str, str]:
        """G√©n√®re commandes pour lancer diff√©rents types de recherche"""
        
        commands = {
            "recherche_prioritaire": """
# Recherche topics prioritaires pour Safety Agentique
python storm_launcher.py --mode priority --topics 10 --output safety_agentique_corpus

# Ou via script Python:
import asyncio
from storm_launcher import StormLauncher

async def main():
    launcher = StormLauncher()
    results = await launcher.launch_storm_research()
    print(f"‚úÖ {len(results)} sujets recherch√©s pour Safety Agentique")

asyncio.run(main())
            """,
            
            "recherche_sectorielle": """
# Recherche sp√©cialis√©e par secteur SCIAN
python storm_launcher.py --mode sectorial --scian 236 --focus construction_safety

# Topics sp√©cifiques construction:
python storm_launcher.py --topics hazard_identification_systematic job_safety_analysis_jsa construction_safety_training
            """,
            
            "enrichissement_continu": """
# Mode enrichissement continu (schedule quotidien)
python storm_launcher.py --mode continuous --schedule daily --batch_size 5

# Mise √† jour corpus existant
python storm_launcher.py --mode update --corpus safety_agentique_corpus_20250706.json --new_topics 3
            """,
            
            "analyse_gaps": """
# Identifier lacunes corpus actuel
python storm_launcher.py --mode analyze_gaps --corpus current --recommend_topics

# Validation qualit√© corpus
python storm_launcher.py --mode validate --corpus safety_agentique_corpus.json --quality_threshold 0.85
            """
        }
        
        return commands

def main():
    """Fonction principale pour tests et d√©monstrations"""
    
    print("üåü STORM LAUNCHER - Safety Agentique Corpus Enhancement")
    print("=" * 60)
    
    launcher = StormLauncher()
    
    # Afficher topics prioritaires
    priority_topics = launcher.get_priority_topics_for_safety_agentique()
    
    print(f"\nüìä {len(priority_topics)} TOPICS PRIORITAIRES IDENTIFI√âS:")
    print("-" * 40)
    
    for topic_info in priority_topics[:10]:  # Top 10
        priority_label = {1: "CRITIQUE", 2: "√âLEV√âE", 3: "MOYENNE"}[topic_info["priority"]]
        print(f"üéØ [{priority_label}] {topic_info['topic']}")
        print(f"   üìÇ Cat√©gorie: {topic_info['category']}")
        print(f"   üí° Impact: {topic_info['safety_agentique_impact']}")
        print()
    
    # Afficher commandes de lancement
    commands = launcher.generate_launch_commands()
    print("\nüöÄ COMMANDES DE LANCEMENT DISPONIBLES:")
    print("=" * 50)
    
    for cmd_type, cmd_text in commands.items():
        print(f"\nüìã {cmd_type.upper()}:")
        print(cmd_text)
    
    # Option lancement interactif
    try:
        choice = input("\n‚ùì Lancer recherche prioritaire maintenant ? (y/N): ").lower()
        if choice == 'y':
            print("üîÑ Lancement recherche STORM...")
            asyncio.run(launcher.launch_storm_research())
        else:
            print("‚ÑπÔ∏è  Utilisez les commandes ci-dessus pour lancer STORM selon vos besoins")
    except KeyboardInterrupt:
        print("\nüëã Au revoir !")

if __name__ == "__main__":
    main()