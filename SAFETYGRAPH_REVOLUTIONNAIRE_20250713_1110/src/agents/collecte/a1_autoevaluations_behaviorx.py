# SafetyAgentic - Agent A1 Enrichi BehaviorX : Auto√©valuations + Safe Self
# =========================================================================
# Int√©gration des modules BehaviorX dans l'agent A1 existant
# Version : Phase 1 - Semaine 1 (5 juillet 2025)

import sys
import os
import asyncio
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
import logging

# Configuration logging SafetyAgentic
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SafetyAgentic.A1.BehaviorX")

@dataclass
class SafetyAgenticState:
    """√âtat unifi√© SafetyAgentic compatible BehaviorX"""
    
    # Donn√©es originales SafetyAgentic
    agent_id: str = "A1_BehaviorX"
    timestamp: datetime = field(default_factory=datetime.now)
    donn√©es_entr√©e: Dict = field(default_factory=dict)
    variables_culture_sst: List[Dict] = field(default_factory=list)
    scores_autoeval: Dict = field(default_factory=dict)
    zones_risque: List[str] = field(default_factory=list)
    
    # Nouveaux champs BehaviorX
    safe_self_data: Dict = field(default_factory=dict)
    comportements_abc: List[Dict] = field(default_factory=list)
    questionnaire_irsst: Dict = field(default_factory=dict)
    score_conscience_augmente: float = 0.0
    facteurs_humains: Dict = field(default_factory=dict)
    
    # M√©triques int√©gr√©es
    fiabilit√©_globale: float = 0.0
    confiance_ia: float = 0.0
    biais_d√©tect√©s: List[str] = field(default_factory=list)

@dataclass
class ModuleBehaviorX:
    """Module BehaviorX int√©gr√© dans SafetyAgentic"""
    
    def safe_self_evaluation(self, donn√©es_autoeval: Dict, contexte_terrain: Dict) -> Dict:
        """
        Module Safe Self de BehaviorX : auto√©valuation comportementale augment√©e
        """
        logger.info("üîÑ Module Safe Self BehaviorX activ√©")
        
        # Analyse comportementale ABC
        antecedents = contexte_terrain.get("antecedents", [])
        comportements = donn√©es_autoeval.get("comportements_observ√©s", [])
        consequences = contexte_terrain.get("consequences_potentielles", [])
        
        # Calcul score conscience augment√© par IA
        score_conscience = self._calculer_conscience_augmentee(
            donn√©es_autoeval, contexte_terrain
        )
        
        # Mapping vers mod√®le ABC
        analyse_abc = {
            "A_antecedents": self._analyser_antecedents(antecedents),
            "B_comportements": self._analyser_comportements(comportements),
            "C_consequences": self._analyser_consequences(consequences),
            "score_abc_global": self._calculer_score_abc(antecedents, comportements, consequences)
        }
        
        logger.info(f"‚úÖ Safe Self termin√© - Score conscience augment√©: {score_conscience:.2f}")
        
        return {
            "score_conscience_augmente": score_conscience,
            "analyse_abc": analyse_abc,
            "patterns_comportementaux": self._identifier_patterns(comportements),
            "recommandations_safe_self": self._generer_recommandations_safe_self(analyse_abc)
        }
    
    def questionnaire_irsst_facteurs_humains(self, donn√©es_autoeval: Dict) -> Dict:
        """
        Questionnaire IRSST facteurs humains int√©gr√©
        """
        logger.info("üîÑ Questionnaire IRSST Facteurs Humains activ√©")
        
        # Variables IRSST facteurs humains
        facteurs_individuels = self._evaluer_facteurs_individuels(donn√©es_autoeval)
        facteurs_organisationnels = self._evaluer_facteurs_organisationnels(donn√©es_autoeval)
        facteurs_environnementaux = self._evaluer_facteurs_environnementaux(donn√©es_autoeval)
        
        # Score global facteurs humains
        score_facteurs_humains = (
            facteurs_individuels["score"] * 0.4 +
            facteurs_organisationnels["score"] * 0.4 +
            facteurs_environnementaux["score"] * 0.2
        )
        
        logger.info(f"‚úÖ Questionnaire IRSST termin√© - Score facteurs humains: {score_facteurs_humains:.2f}")
        
        return {
            "score_facteurs_humains": score_facteurs_humains,
            "facteurs_individuels": facteurs_individuels,
            "facteurs_organisationnels": facteurs_organisationnels,
            "facteurs_environnementaux": facteurs_environnementaux,
            "conformit√©_irsst": score_facteurs_humains >= 7.0
        }
    
    def interface_mobile_terrain(self, localisation: Dict, contexte_t√¢che: Dict) -> Dict:
        """
        Interface mobile BehaviorX pour terrain optimis√©e
        """
        logger.info("üì± Interface mobile BehaviorX terrain activ√©e")
        
        # Adaptation interface selon contexte
        mode_interface = self._determiner_mode_interface(localisation, contexte_t√¢che)
        
        # G√©n√©ration formulaires adaptatifs
        formulaires = self._generer_formulaires_adaptatifs(contexte_t√¢che)
        
        # Guidage vocal/visuel
        guidage = self._activer_guidage_intelligent(mode_interface, contexte_t√¢che)
        
        return {
            "mode_interface": mode_interface,
            "formulaires_adaptatifs": formulaires,
            "guidage_intelligent": guidage,
            "temps_completion_estime": self._estimer_temps_completion(formulaires)
        }
    
    def _calculer_conscience_augmentee(self, autoeval: Dict, contexte: Dict) -> float:
        """Calcul IA du score de conscience s√©curit√© augment√©"""
        # Score base auto√©valuation
        score_base = sum(autoeval.get("scores", {}).values()) / len(autoeval.get("scores", {1: 5}))
        
        # Facteur contexte terrain
        facteur_contexte = contexte.get("niveau_risque", 5) / 10
        
        # Facteur coh√©rence r√©ponses
        facteur_coherence = autoeval.get("coherence", 0.8)
        
        # IA augmentation : pr√©diction comportement futur
        facteur_ia = min(1.0, score_base * facteur_contexte * facteur_coherence * 1.2)
        
        return min(10.0, facteur_ia * 10)
    
    def _analyser_antecedents(self, antecedents: List) -> Dict:
        """Analyse des ant√©c√©dents dans mod√®le ABC"""
        if not antecedents:
            return {"score": 5.0, "risques_identifi√©s": [], "niveau": "MOYEN"}
        
        risques = [a for a in antecedents if "risque" in str(a).lower()]
        score = max(1, 10 - len(risques) * 2)
        niveau = "√âLEV√â" if score >= 8 else "MOYEN" if score >= 5 else "FAIBLE"
        
        return {
            "score": score,
            "risques_identifi√©s": risques,
            "niveau": niveau,
            "patterns": self._identifier_patterns_antecedents(antecedents)
        }
    
    def _analyser_comportements(self, comportements: List) -> Dict:
        """Analyse des comportements observ√©s"""
        if not comportements:
            return {"score": 7.0, "comportements_s√ªrs": 0, "comportements_risque": 0}
        
        comportements_s√ªrs = len([c for c in comportements if "s√ªr" in str(c).lower() or "s√©curitaire" in str(c).lower()])
        comportements_risque = len([c for c in comportements if "risque" in str(c).lower() or "danger" in str(c).lower()])
        
        score = min(10, max(1, 7 + comportements_s√ªrs - comportements_risque * 2))
        
        return {
            "score": score,
            "comportements_s√ªrs": comportements_s√ªrs,
            "comportements_risque": comportements_risque,
            "ratio_s√©curit√©": comportements_s√ªrs / max(1, len(comportements))
        }
    
    def _analyser_consequences(self, consequences: List) -> Dict:
        """Analyse des cons√©quences potentielles"""
        if not consequences:
            return {"score": 6.0, "severity": "MOYEN", "probabilit√©": 0.3}
        
        severit√©_mots = ["grave", "mortel", "critique", "majeur"]
        consequences_graves = len([c for c in consequences if any(mot in str(c).lower() for mot in severit√©_mots)])
        
        score = max(1, 8 - consequences_graves * 3)
        severity = "√âLEV√â" if consequences_graves > 0 else "MOYEN"
        probabilit√© = min(0.9, consequences_graves * 0.3 + 0.1)
        
        return {
            "score": score,
            "severity": severity,
            "probabilit√©": probabilit√©,
            "consequences_graves": consequences_graves
        }
    
    def _calculer_score_abc(self, antecedents: List, comportements: List, consequences: List) -> float:
        """Score global mod√®le ABC int√©gr√©"""
        score_a = self._analyser_antecedents(antecedents)["score"]
        score_b = self._analyser_comportements(comportements)["score"]
        score_c = self._analyser_consequences(consequences)["score"]
        
        # Pond√©ration ABC : Comportement prioritaire
        return (score_a * 0.3 + score_b * 0.5 + score_c * 0.2)
    
    def _identifier_patterns(self, comportements: List) -> List[str]:
        """Identification patterns comportementaux par IA"""
        patterns = []
        if not comportements:
            return ["pattern_insufficient_data"]
        
        # Patterns de s√©curit√©
        if any("epi" in str(c).lower() for c in comportements):
            patterns.append("usage_epi_conscient")
        if any("proc√©dure" in str(c).lower() for c in comportements):
            patterns.append("respect_proc√©dures")
        if any("v√©rification" in str(c).lower() for c in comportements):
            patterns.append("v√©rifications_syst√©matiques")
        
        return patterns or ["pattern_standard"]
    
    def _generer_recommandations_safe_self(self, analyse_abc: Dict) -> List[str]:
        """G√©n√©ration recommandations Safe Self personnalis√©es"""
        recommandations = []
        
        score_abc = analyse_abc["score_abc_global"]
        
        if score_abc < 5:
            recommandations.append("Formation imm√©diate mod√®le ABC recommand√©e")
            recommandations.append("R√©vision des proc√©dures de s√©curit√© prioritaire")
        elif score_abc < 7:
            recommandations.append("Renforcement conscience comportementale")
            recommandations.append("Sessions coaching s√©curit√© personnalis√©es")
        else:
            recommandations.append("Maintien excellent niveau conscience s√©curit√©")
            recommandations.append("Partage bonnes pratiques avec √©quipe")
        
        return recommandations
    
    def _evaluer_facteurs_individuels(self, donn√©es: Dict) -> Dict:
        """√âvaluation facteurs individuels IRSST"""
        scores = donn√©es.get("scores", {})
        score_moyen = sum(scores.values()) / len(scores) if scores else 7.0
        
        return {
            "score": score_moyen,
            "comp√©tences_techniques": score_moyen * 0.9,
            "motivation_s√©curit√©": score_moyen * 1.1,
            "stress_fatigue": max(1, 10 - score_moyen),
            "formation_re√ßue": score_moyen >= 7
        }
    
    def _evaluer_facteurs_organisationnels(self, donn√©es: Dict) -> Dict:
        """√âvaluation facteurs organisationnels IRSST"""
        score_base = donn√©es.get("organisation_travail", 7.0)
        
        return {
            "score": score_base,
            "politique_s√©curit√©": score_base >= 8,
            "communication_√©quipe": score_base * 0.9,
            "ressources_disponibles": score_base * 1.1,
            "culture_s√©curit√©": score_base >= 7
        }
    
    def _evaluer_facteurs_environnementaux(self, donn√©es: Dict) -> Dict:
        """√âvaluation facteurs environnementaux IRSST"""
        score_base = donn√©es.get("conditions_travail", 7.0)
        
        return {
            "score": score_base,
            "conditions_physiques": score_base,
            "√©quipements_disponibles": score_base >= 7,
            "espaces_travail": score_base * 0.95,
            "facteurs_externes": max(1, score_base - 1)
        }
    
    def _determiner_mode_interface(self, localisation: Dict, contexte: Dict) -> str:
        """D√©termine le mode interface optimal"""
        if contexte.get("niveau_bruit", 0) > 7:
            return "visuel_augment√©"
        elif localisation.get("√©clairage", 10) < 5:
            return "vocal_prioritaire"
        else:
            return "mixte_adaptatif"
    
    def _generer_formulaires_adaptatifs(self, contexte: Dict) -> List[Dict]:
        """G√©n√©ration formulaires adaptatifs selon contexte"""
        niveau_risque = contexte.get("niveau_risque", 5)
        
        if niveau_risque >= 8:
            return [
                {"type": "urgence", "questions": 3, "temps_max": "30s"},
                {"type": "s√©curit√©_critique", "questions": 5, "temps_max": "60s"}
            ]
        elif niveau_risque >= 5:
            return [
                {"type": "standard", "questions": 8, "temps_max": "2min"},
                {"type": "comportemental", "questions": 10, "temps_max": "3min"}
            ]
        else:
            return [
                {"type": "complet", "questions": 15, "temps_max": "5min"},
                {"type": "culture_sst", "questions": 20, "temps_max": "7min"}
            ]
    
    def _activer_guidage_intelligent(self, mode: str, contexte: Dict) -> Dict:
        """Activation guidage intelligent selon mode"""
        return {
            "mode_actif": mode,
            "vocal_activ√©": "vocal" in mode,
            "visuel_augment√©": "visuel" in mode,
            "adaptation_temps_r√©el": True,
            "niveau_assistance": "√©lev√©" if contexte.get("complexit√©", 5) >= 7 else "standard"
        }
    
    def _estimer_temps_completion(self, formulaires: List[Dict]) -> Dict:
        """Estimation temps de completion"""
        temps_total = sum(
            int(f.get("temps_max", "60s").replace("s", "").replace("min", "").replace("h", "")) 
            for f in formulaires
        )
        
        return {
            "temps_estime_secondes": temps_total,
            "temps_humain": f"{temps_total//60}min {temps_total%60}s" if temps_total >= 60 else f"{temps_total}s",
            "complexit√©": "simple" if temps_total <= 120 else "mod√©r√©e" if temps_total <= 300 else "complexe"
        }
    
    def _identifier_patterns_antecedents(self, antecedents: List) -> List[str]:
        """Identification patterns dans ant√©c√©dents"""
        patterns = []
        if any("pression" in str(a).lower() for a in antecedents):
            patterns.append("pression_temporelle")
        if any("formation" in str(a).lower() for a in antecedents):
            patterns.append("formation_insuffisante")
        if any("√©quipement" in str(a).lower() for a in antecedents):
            patterns.append("d√©faillance_√©quipement")
        
        return patterns or ["pattern_ind√©termin√©"]

class A1CollecteurAutoEvaluationsBehaviorX:
    """
    Agent A1 Enrichi BehaviorX : Auto√©valuations + Safe Self + IRSST
    Int√©gration compl√®te des modules BehaviorX dans SafetyAgentic
    """
    
    def __init__(self):
        self.agent_id = "A1_BehaviorX_Enrichi"
        self.version = "1.0_Phase1"
        self.behaviorx_module = ModuleBehaviorX()
        logger.info(f"ü§ñ Agent A1 BehaviorX initialis√© - Version {self.version}")
    
    async def process(self, state: SafetyAgenticState) -> SafetyAgenticState:
        """
        Traitement enrichi A1 + BehaviorX
        """
        start_time = datetime.now()
        logger.info("üîÑ D√©marrage traitement Agent A1 BehaviorX Enrichi")
        
        try:
            # √âtape 1 : Safe Self BehaviorX
            safe_self_result = self.behaviorx_module.safe_self_evaluation(
                state.donn√©es_entr√©e.get("auto√©valuation", {}),
                state.donn√©es_entr√©e.get("contexte_terrain", {})
            )
            state.safe_self_data = safe_self_result
            state.score_conscience_augmente = safe_self_result["score_conscience_augmente"]
            state.comportements_abc = [safe_self_result["analyse_abc"]]
            
            # √âtape 2 : Questionnaire IRSST
            irsst_result = self.behaviorx_module.questionnaire_irsst_facteurs_humains(
                state.donn√©es_entr√©e.get("auto√©valuation", {})
            )
            state.questionnaire_irsst = irsst_result
            state.facteurs_humains = irsst_result
            
            # √âtape 3 : Interface mobile terrain
            interface_result = self.behaviorx_module.interface_mobile_terrain(
                state.donn√©es_entr√©e.get("localisation", {}),
                state.donn√©es_entr√©e.get("contexte_t√¢che", {})
            )
            
            # √âtape 4 : Calcul m√©triques int√©gr√©es
            state.fiabilit√©_globale = self._calculer_fiabilit√©_globale(safe_self_result, irsst_result)
            state.confiance_ia = self._calculer_confiance_ia(safe_self_result, irsst_result)
            state.biais_d√©tect√©s = self._detecter_biais_integres(safe_self_result, irsst_result)
            
            # √âtape 5 : Mapping variables culture SST enrichies
            state.variables_culture_sst = self._mapper_variables_culture_enrichies(
                safe_self_result, irsst_result
            )
            
            # Performance logging
            temps_traitement = (datetime.now() - start_time).total_seconds()
            logger.info(f"üìä Performance A1 BehaviorX: {temps_traitement:.3f}s, confiance: {state.confiance_ia:.2f}")
            logger.info(f"‚úÖ Agent A1 BehaviorX termin√© - Score global: {state.fiabilit√©_globale:.2f}")
            
            return state
            
        except Exception as e:
            logger.error(f"‚ùå Erreur Agent A1 BehaviorX: {str(e)}")
            state.biais_d√©tect√©s.append("erreur_traitement")
            return state
    
    def _calculer_fiabilit√©_globale(self, safe_self: Dict, irsst: Dict) -> float:
        """Calcul fiabilit√© globale int√©gr√©e BehaviorX + SafetyAgentic"""
        score_safe_self = safe_self["score_conscience_augmente"] / 10
        score_irsst = irsst["score_facteurs_humains"] / 10
        score_abc = safe_self["analyse_abc"]["score_abc_global"] / 10
        
        # Pond√©ration : Safe Self 40%, IRSST 35%, ABC 25%
        return min(1.0, score_safe_self * 0.4 + score_irsst * 0.35 + score_abc * 0.25)
    
    def _calculer_confiance_ia(self, safe_self: Dict, irsst: Dict) -> float:
        """Calcul confiance IA sur les r√©sultats"""
        # Facteurs de confiance
        coherence_safe_self = 0.9  # Simulation haute coh√©rence
        conformit√©_irsst = 1.0 if irsst["conformit√©_irsst"] else 0.7
        richesse_donn√©es = min(1.0, len(safe_self.get("patterns_comportementaux", [])) / 3)
        
        return min(1.0, (coherence_safe_self + conformit√©_irsst + richesse_donn√©es) / 3)
    
    def _detecter_biais_integres(self, safe_self: Dict, irsst: Dict) -> List[str]:
        """D√©tection biais int√©gr√©s BehaviorX + IRSST"""
        biais = []
        
        # Biais Safe Self
        if safe_self["score_conscience_augmente"] > 9.5:
            biais.append("surconfiance_safe_self")
        
        # Biais IRSST
        if irsst["score_facteurs_humains"] > 9.0 and irsst["facteurs_individuels"]["stress_fatigue"] < 2:
            biais.append("optimisme_irsst")
        
        # Biais ABC
        score_abc = safe_self["analyse_abc"]["score_abc_global"]
        if score_abc > 9.0:
            biais.append("id√©alisation_comportementale")
        
        return biais
    
    def _mapper_variables_culture_enrichies(self, safe_self: Dict, irsst: Dict) -> List[Dict]:
        """Mapping enrichi variables culture SST avec BehaviorX"""
        variables = []
        
        # Variables Safe Self
        variables.append({
            "nom": "Conscience comportementale augment√©e",
            "valeur": safe_self["score_conscience_augmente"],
            "confiance": 0.95,
            "source": "BehaviorX_Safe_Self"
        })
        
        # Variables ABC
        abc_data = safe_self["analyse_abc"]
        variables.extend([
            {
                "nom": "Gestion ant√©c√©dents",
                "valeur": abc_data["A_antecedents"]["score"],
                "confiance": 0.90,
                "source": "BehaviorX_ABC"
            },
            {
                "nom": "Qualit√© comportements",
                "valeur": abc_data["B_comportements"]["score"],
                "confiance": 0.95,
                "source": "BehaviorX_ABC"
            },
            {
                "nom": "√âvaluation cons√©quences",
                "valeur": abc_data["C_consequences"]["score"],
                "confiance": 0.85,
                "source": "BehaviorX_ABC"
            }
        ])
        
        # Variables IRSST
        variables.extend([
            {
                "nom": "Facteurs individuels IRSST",
                "valeur": irsst["facteurs_individuels"]["score"],
                "confiance": 0.90,
                "source": "IRSST_Facteurs_Humains"
            },
            {
                "nom": "Facteurs organisationnels IRSST",
                "valeur": irsst["facteurs_organisationnels"]["score"],
                "confiance": 0.85,
                "source": "IRSST_Facteurs_Humains"
            },
            {
                "nom": "Facteurs environnementaux IRSST",
                "valeur": irsst["facteurs_environnementaux"]["score"],
                "confiance": 0.80,
                "source": "IRSST_Facteurs_Humains"
            }
        ])
        
        return variables

# Test int√©gr√© A1 BehaviorX
async def test_agent_a1_behaviorx():
    """Test complet Agent A1 enrichi BehaviorX"""
    print("üß™ TEST AGENT A1 BEHAVIORX ENRICHI")
    print("=" * 50)
    
    # Donn√©es de test enrichies
    state = SafetyAgenticState(
        donn√©es_entr√©e={
            "auto√©valuation": {
                "scores": {
                    "usage_epi": 8.0,
                    "respect_proc√©dures": 7.5,
                    "communication_√©quipe": 8.5,
                    "gestion_stress": 7.0,
                    "formation_continue": 8.0
                },
                "comportements_observ√©s": [
                    "port casque syst√©matique",
                    "v√©rification √©quipements avant usage",
                    "communication dangers identifi√©s",
                    "respect proc√©dures lockout"
                ],
                "organisation_travail": 7.5,
                "conditions_travail": 7.0,
                "coherence": 0.92
            },
            "contexte_terrain": {
                "antecedents": [
                    "formation r√©cente EPI",
                    "nouvelle proc√©dure mise en place",
                    "√©quipement v√©rifi√© ce matin"
                ],
                "consequences_potentielles": [
                    "accident √©vit√© par vigilance",
                    "am√©lioration s√©curit√© √©quipe"
                ],
                "niveau_risque": 6,
                "√©clairage": 8,
                "niveau_bruit": 4
            },
            "contexte_t√¢che": {
                "complexit√©": 6,
                "niveau_risque": 6,
                "dur√©e_pr√©vue": "2h"
            },
            "localisation": {
                "zone": "atelier_fabrication",
                "√©clairage": 8,
                "temp√©rature": 22
            }
        }
    )
    
    # Test agent
    agent = A1CollecteurAutoEvaluationsBehaviorX()
    r√©sultat = await agent.process(state)
    
    # Affichage r√©sultats
    print(f"\nüìä R√âSULTATS AGENT A1 BEHAVIORX:")
    print(f"=" * 40)
    print(f"‚úÖ Score conscience augment√©: {r√©sultat.score_conscience_augmente:.2f}/10")
    print(f"‚úÖ Fiabilit√© globale: {r√©sultat.fiabilit√©_globale:.3f}")
    print(f"‚úÖ Confiance IA: {r√©sultat.confiance_ia:.3f}")
    print(f"‚úÖ Variables culture enrichies: {len(r√©sultat.variables_culture_sst)}")
    print(f"‚úÖ Biais d√©tect√©s: {len(r√©sultat.biais_d√©tect√©s)}")
    
    print(f"\nüéØ MODULES BEHAVIORX:")
    print(f"üì± Safe Self - Score ABC: {r√©sultat.safe_self_data['analyse_abc']['score_abc_global']:.2f}")
    print(f"üìã IRSST - Conformit√©: {r√©sultat.questionnaire_irsst['conformit√©_irsst']}")
    print(f"üß† Patterns d√©tect√©s: {len(r√©sultat.safe_self_data.get('patterns_comportementaux', []))}")
    
    print(f"\nüí° RECOMMANDATIONS SAFE SELF:")
    for rec in r√©sultat.safe_self_data.get("recommandations_safe_self", []):
        print(f"  - {rec}")
    
    print(f"\n‚úÖ Test Agent A1 BehaviorX termin√© avec succ√®s!")
    return r√©sultat

if __name__ == "__main__":
    asyncio.run(test_agent_a1_behaviorx())