# Test AN1 Standalone - Analyste Ã‰carts SafetyAgentic
# ===================================================
# Version autonome sans imports externes

import asyncio
import numpy as np
from datetime import datetime
import logging

# Configuration logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("SafetyAgentic.AN1")

class AN1AnalysteEcarts:
    """
    Agent AN1 - Analyste des Ã‰carts Culture SÃ©curitÃ©
    Version standalone pour test
    """
    
    def __init__(self):
        """Initialisation Agent AN1"""
        self.agent_id = "AN1"
        self.agent_name = "Analyste Ã‰carts"
        self.version = "1.0.0"
        
        # ModÃ¨les HSE intÃ©grÃ©s
        self.hse_models = {
            "hfacs_l1": "Ã‰checs organisationnels",
            "hfacs_l2": "Supervision inadÃ©quate", 
            "hfacs_l3": "Actes/conditions prÃ©curseurs",
            "hfacs_l4": "Actes/conditions dangereux",
            "swiss_cheese": "DÃ©faillances barriÃ¨res",
            "srk": "Niveaux comportement (Skill-Rule-Knowledge)",
            "reason": "Erreurs actives vs latentes",
            "bow_tie": "Analyse barriÃ¨res prÃ©ventives/protectives"
        }
        
        # Seuils d'Ã©carts critiques
        self.ecart_thresholds = {
            "faible": 10,      # Ã‰cart < 10% = acceptable
            "modere": 25,      # Ã‰cart 10-25% = Ã  surveiller
            "eleve": 50,       # Ã‰cart 25-50% = critique
            "critique": 100    # Ã‰cart > 50% = zone aveugle majeure
        }
        
        logger.info(f"ğŸ¤– Agent {self.agent_id} ({self.agent_name}) initialisÃ©")
        print(f"ğŸ¤– Agent {self.agent_id} ({self.agent_name}) initialisÃ©")
    
    async def process(self, data_a1, data_a2, context=None):
        """Traitement principal: analyser Ã©carts A1 vs A2"""
        start_time = datetime.now()
        logger.info("ğŸ”„ DÃ©marrage traitement Agent AN1")
        
        try:
            # 1. Validation donnÃ©es d'entrÃ©e
            self._validate_input_data(data_a1, data_a2)
            logger.info("âœ… Validation des donnÃ©es d'entrÃ©e rÃ©ussie")
            
            # 2. Calcul Ã©carts variables culture SST
            ecarts_variables = self._calculate_culture_gaps(data_a1, data_a2)
            
            # 3. Application des modÃ¨les HSE
            analysis_hse = self._apply_hse_models(ecarts_variables, context)
            
            # 4. Identification zones aveugles
            zones_aveugles = self._identify_blind_spots(ecarts_variables)
            
            # 5. Calcul scores rÃ©alisme culturel
            realisme_scores = self._calculate_realism_scores(data_a1, data_a2)
            
            # 6. GÃ©nÃ©ration recommandations ciblÃ©es
            recommendations = self._generate_targeted_recommendations(
                ecarts_variables, zones_aveugles, analysis_hse
            )
            
            # 7. Calcul mÃ©triques performance
            performance_time = (datetime.now() - start_time).total_seconds()
            confidence_score = self._calculate_confidence_score(ecarts_variables)
            
            logger.info(f"ğŸ“Š Performance AN1: {performance_time:.2f}s, confidence: {confidence_score:.2f}")
            
            # 8. Construction rÃ©sultat final
            result = {
                "agent_info": {
                    "agent_id": self.agent_id,
                    "agent_name": self.agent_name,
                    "version": self.version,
                    "timestamp": datetime.now().isoformat(),
                    "performance_time": performance_time,
                    "confidence_score": confidence_score
                },
                "ecarts_analysis": {
                    "ecarts_variables": ecarts_variables,
                    "zones_aveugles": zones_aveugles,
                    "realisme_scores": realisme_scores,
                    "nombre_ecarts_critiques": len([e for e in ecarts_variables.values() if e.get("niveau") == "critique"])
                },
                "hse_models_analysis": analysis_hse,
                "recommendations": recommendations,
                "summary": {
                    "ecart_moyen": np.mean([e.get("pourcentage", 0) for e in ecarts_variables.values()]),
                    "variables_critiques": len(zones_aveugles),
                    "actions_recommandees": len(recommendations),
                    "priorite_intervention": self._determine_intervention_priority(zones_aveugles)
                }
            }
            
            logger.info(f"âœ… Agent AN1 terminÃ© - Score confiance: {confidence_score:.2f}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Erreur Agent AN1: {str(e)}")
            return {"error": str(e), "agent_id": self.agent_id}
    
    def _validate_input_data(self, data_a1, data_a2):
        """Validation des donnÃ©es A1 et A2"""
        if not data_a1 or not data_a2:
            raise ValueError("DonnÃ©es A1 ou A2 manquantes")
        
        required_a1 = ["variables_culture_sst"]
        required_a2 = ["variables_culture_terrain"]
        
        for field in required_a1:
            if field not in data_a1:
                raise ValueError(f"Champ manquant A1: {field}")
                
        for field in required_a2:
            if field not in data_a2:
                raise ValueError(f"Champ manquant A2: {field}")
    
    def _calculate_culture_gaps(self, data_a1, data_a2):
        """Calcul Ã©carts entre variables culture A1 vs A2"""
        ecarts = {}
        
        vars_a1 = data_a1.get("variables_culture_sst", {})
        vars_a2 = data_a2.get("variables_culture_terrain", {})
        
        for variable in set(vars_a1.keys()).intersection(set(vars_a2.keys())):
            score_a1 = vars_a1[variable].get("score", 0)
            score_a2 = vars_a2[variable].get("score", 0)
            
            # Calcul Ã©cart relatif
            if score_a1 > 0:
                ecart_pct = abs(score_a1 - score_a2) / score_a1 * 100
            else:
                ecart_pct = abs(score_a2) * 10
            
            # Classification niveau Ã©cart
            if ecart_pct < self.ecart_thresholds["faible"]:
                niveau = "faible"
            elif ecart_pct < self.ecart_thresholds["modere"]:
                niveau = "modere"
            elif ecart_pct < self.ecart_thresholds["eleve"]:
                niveau = "eleve"
            else:
                niveau = "critique"
            
            ecarts[variable] = {
                "score_autoeval": score_a1,
                "score_terrain": score_a2,
                "ecart_absolu": abs(score_a1 - score_a2),
                "pourcentage": ecart_pct,
                "niveau": niveau,
                "direction": "surestimation" if score_a1 > score_a2 else "sous_estimation",
                "variable_source_a1": vars_a1[variable].get("source", "unknown"),
                "variable_source_a2": vars_a2[variable].get("source", "unknown")
            }
        
        return ecarts
    
    def _apply_hse_models(self, ecarts_variables, context=None):
        """Application des modÃ¨les HSE sur les Ã©carts"""
        hse_analysis = {}
        
        for model_code, model_name in self.hse_models.items():
            if model_code.startswith("hfacs"):
                analysis = self._apply_hfacs_model(model_code, ecarts_variables)
            elif model_code == "swiss_cheese":
                analysis = self._apply_swiss_cheese_model(ecarts_variables)
            elif model_code == "srk":
                analysis = self._apply_srk_model(ecarts_variables)
            else:
                analysis = self._apply_generic_hse_model(model_code, ecarts_variables)
            
            hse_analysis[model_code] = {
                "model_name": model_name,
                "analysis": analysis,
                "variables_impliquees": len([v for v in ecarts_variables.keys() 
                                           if ecarts_variables[v]["niveau"] in ["eleve", "critique"]]),
                "score_applicabilite": self._calculate_model_applicability(model_code, ecarts_variables)
            }
        
        return hse_analysis
    
    def _apply_hfacs_model(self, level, ecarts):
        """Application modÃ¨le HFACS selon niveau"""
        hfacs_mapping = {
            "hfacs_l1": ["leadership_sst", "politique_securite"],
            "hfacs_l2": ["supervision_directe", "formation_securite"],
            "hfacs_l3": ["usage_epi", "respect_procedures"],
            "hfacs_l4": ["comportements_risque", "communication_risques"]
        }
        
        variables_concernees = hfacs_mapping.get(level, [])
        ecarts_niveau = {v: ecarts[v] for v in variables_concernees if v in ecarts}
        
        score_defaillance = np.mean([e["pourcentage"] for e in ecarts_niveau.values()]) if ecarts_niveau else 0
        
        return {
            "niveau_hfacs": level,
            "variables_analysees": len(ecarts_niveau),
            "ecarts_critiques": len([e for e in ecarts_niveau.values() if e["niveau"] == "critique"]),
            "score_defaillance": score_defaillance,
            "interpretation": self._interpret_hfacs_level(level, score_defaillance)
        }
    
    def _interpret_hfacs_level(self, level, score):
        """InterprÃ©tation du score HFACS par niveau"""
        interpretations = {
            "hfacs_l1": f"DÃ©faillances organisationnelles: {score:.1f}% - Engagement leadership",
            "hfacs_l2": f"Supervision inadÃ©quate: {score:.1f}% - Encadrement terrain", 
            "hfacs_l3": f"Conditions prÃ©curseurs: {score:.1f}% - PrÃ©vention incidents",
            "hfacs_l4": f"Actes dangereux: {score:.1f}% - Comportements risque"
        }
        return interpretations.get(level, f"Analyse {level}: {score:.1f}%")
    
    def _apply_swiss_cheese_model(self, ecarts):
        """Application modÃ¨le Swiss Cheese"""
        barrieres = {
            "organisationnelles": ["leadership_sst", "formation_securite"],
            "supervision": ["supervision_directe", "communication_risques"],
            "individuelles": ["usage_epi", "respect_procedures"]
        }
        
        defaillances = {}
        for barriere_type, variables in barrieres.items():
            ecarts_barriere = {v: ecarts[v] for v in variables if v in ecarts}
            if ecarts_barriere:
                defaillance_score = np.mean([e["pourcentage"] for e in ecarts_barriere.values()])
                defaillances[barriere_type] = {
                    "score_defaillance": defaillance_score,
                    "variables_impliquees": list(ecarts_barriere.keys()),
                    "niveau_risque": "high" if defaillance_score > 30 else "medium" if defaillance_score > 15 else "low"
                }
        
        return {
            "defaillances_barrieres": defaillances,
            "risque_global": max([d["score_defaillance"] for d in defaillances.values()]) if defaillances else 0,
            "barrieres_critiques": [k for k, v in defaillances.items() if v["niveau_risque"] == "high"]
        }
    
    def _apply_srk_model(self, ecarts):
        """Application modÃ¨le SRK"""
        srk_mapping = {
            "skill": ["usage_epi", "competences_techniques"],
            "rule": ["respect_procedures", "formation_securite"],
            "knowledge": ["communication_risques", "supervision_directe"]
        }
        
        srk_analysis = {}
        for niveau, variables in srk_mapping.items():
            ecarts_niveau = {v: ecarts[v] for v in variables if v in ecarts}
            if ecarts_niveau:
                score_ecart = np.mean([e["pourcentage"] for e in ecarts_niveau.values()])
                srk_analysis[niveau] = {
                    "score_ecart": score_ecart,
                    "variables_count": len(ecarts_niveau),
                    "niveau_defaillance": "critique" if score_ecart > 40 else "eleve" if score_ecart > 20 else "faible"
                }
        
        return srk_analysis
    
    def _apply_generic_hse_model(self, model_code, ecarts):
        """Analyse gÃ©nÃ©rique pour autres modÃ¨les HSE"""
        return {
            "model_code": model_code,
            "variables_analysees": len(ecarts),
            "score_global": np.mean([e["pourcentage"] for e in ecarts.values()]) if ecarts else 0
        }
    
    def _identify_blind_spots(self, ecarts_variables):
        """Identification zones aveugles culture sÃ©curitÃ©"""
        zones_aveugles = []
        
        for variable, ecart_data in ecarts_variables.items():
            if ecart_data["niveau"] in ["eleve", "critique"]:
                zone_aveugle = {
                    "variable": variable,
                    "type_ecart": ecart_data["direction"],
                    "pourcentage_ecart": ecart_data["pourcentage"],
                    "niveau_critique": ecart_data["niveau"],
                    "score_autoeval": ecart_data["score_autoeval"],
                    "score_terrain": ecart_data["score_terrain"],
                    "explication": self._explain_blind_spot(variable, ecart_data),
                    "impact_potentiel": self._assess_blind_spot_impact(variable, ecart_data)
                }
                zones_aveugles.append(zone_aveugle)
        
        zones_aveugles.sort(key=lambda x: x["pourcentage_ecart"], reverse=True)
        return zones_aveugles
    
    def _explain_blind_spot(self, variable, ecart_data):
        """Explication textuelle de la zone aveugle"""
        direction = ecart_data["direction"]
        pct = ecart_data["pourcentage"]
        
        if direction == "surestimation":
            return f"Surestimation de {pct:.1f}% sur {variable}. L'Ã©quipe pense mieux performer qu'en rÃ©alitÃ©."
        else:
            return f"Sous-estimation de {pct:.1f}% sur {variable}. Performance terrain supÃ©rieure aux perceptions."
    
    def _assess_blind_spot_impact(self, variable, ecart_data):
        """Ã‰valuation impact potentiel zone aveugle"""
        variable_criticality = {
            "usage_epi": "high",
            "respect_procedures": "high", 
            "supervision_directe": "high",
            "formation_securite": "medium",
            "communication_risques": "medium"
        }
        
        criticality = variable_criticality.get(variable, "medium")
        ecart_level = ecart_data["niveau"]
        
        if criticality == "high" and ecart_level == "critique":
            return "CRITIQUE - Risque incident majeur"
        elif criticality == "high" or ecart_level == "critique":
            return "Ã‰LEVÃ‰ - Intervention urgente requise"
        else:
            return "MODÃ‰RÃ‰ - Surveillance renforcÃ©e"
    
    def _calculate_realism_scores(self, data_a1, data_a2):
        """Calcul scores rÃ©alisme culturel"""
        scores_a1 = data_a1.get("scores_autoeval", {})
        observations_a2 = data_a2.get("observations", {})
        
        score_global_a1 = scores_a1.get("score_global", 70)
        score_comportement_a2 = observations_a2.get("score_comportement", 50)
        
        realisme_global = max(0, 100 - abs(score_global_a1 - score_comportement_a2))
        
        return {
            "realisme_global": realisme_global,
            "fiabilite_autoeval": min(100, realisme_global + 10),
            "coherence_perception": realisme_global,
            "niveau_autocritique": "Ã©levÃ©" if realisme_global > 80 else "moyen" if realisme_global > 60 else "faible"
        }
    
    def _generate_targeted_recommendations(self, ecarts, zones_aveugles, hse_analysis):
        """GÃ©nÃ©ration recommandations ciblÃ©es"""
        recommendations = []
        
        # Recommandations par zone aveugle
        for zone in zones_aveugles[:5]:
            rec = {
                "type": "zone_aveugle",
                "priorite": "URGENTE" if zone["niveau_critique"] == "critique" else "Ã‰LEVÃ‰E",
                "variable_cible": zone["variable"],
                "action": f"Corriger Ã©cart {zone['type_ecart']} de {zone['pourcentage_ecart']:.1f}% sur {zone['variable']}",
                "methode": self._recommend_correction_method(zone["variable"], zone["type_ecart"]),
                "timeline": "2-4 semaines" if zone["niveau_critique"] == "critique" else "1-2 mois",
                "ressources_requises": self._estimate_resources(zone["variable"], zone["pourcentage_ecart"])
            }
            recommendations.append(rec)
        
        # Recommandations gÃ©nÃ©rales
        if len(zones_aveugles) > 2:
            recommendations.append({
                "type": "global",
                "priorite": "Ã‰LEVÃ‰E", 
                "action": "Programme amÃ©lioration culture sÃ©curitÃ© globale",
                "methode": "Formation management + observations terrain systÃ©matiques",
                "timeline": "3-6 mois"
            })
        
        return recommendations
    
    def _recommend_correction_method(self, variable, direction):
        """Recommandation mÃ©thode correction"""
        methods = {
            "usage_epi": {
                "surestimation": "Observations terrain ciblÃ©es + formations pratiques",
                "sous_estimation": "Sensibilisation performance + reconnaissance efforts"
            },
            "supervision_directe": {
                "surestimation": "Formation superviseurs + audits conformitÃ©",
                "sous_estimation": "Valorisation encadrement + outils supervision"
            },
            "respect_procedures": {
                "surestimation": "Audit conformitÃ© + coaching terrain",
                "sous_estimation": "Communication succÃ¨s + reconnaissance"
            }
        }
        
        return methods.get(variable, {}).get(direction, "Formation ciblÃ©e + suivi renforcÃ©")
    
    def _estimate_resources(self, variable, ecart_pct):
        """Estimation ressources requises"""
        if ecart_pct > 50:
            return "Ressources importantes - Formation complÃ¨te Ã©quipe"
        elif ecart_pct > 25:
            return "Ressources modÃ©rÃ©es - Formation superviseurs"
        else:
            return "Ressources limitÃ©es - Sensibilisation ciblÃ©e"
    
    def _calculate_model_applicability(self, model_code, ecarts):
        """Calcul score applicabilitÃ© modÃ¨le"""
        variables_critiques = len([e for e in ecarts.values() if e["niveau"] in ["eleve", "critique"]])
        total_variables = len(ecarts) if ecarts else 1
        
        base_score = (variables_critiques / total_variables) * 100
        return min(95, max(20, base_score + 20))
    
    def _calculate_confidence_score(self, ecarts_variables):
        """Calcul score confiance global"""
        if not ecarts_variables:
            return 0.5
        
        coherence = np.mean([1 - min(1, e["pourcentage"] / 100) for e in ecarts_variables.values()])
        completude = min(1.0, len(ecarts_variables) / 8)
        
        return max(0.3, min(0.95, (coherence * 0.7) + (completude * 0.3)))
    
    def _determine_intervention_priority(self, zones_aveugles):
        """DÃ©termination prioritÃ© intervention"""
        if not zones_aveugles:
            return "FAIBLE"
        
        critiques = len([z for z in zones_aveugles if z["niveau_critique"] == "critique"])
        eleves = len([z for z in zones_aveugles if z["niveau_critique"] == "eleve"])
        
        if critiques >= 3:
            return "URGENTE"
        elif critiques >= 1 or eleves >= 5:
            return "Ã‰LEVÃ‰E"
        elif eleves >= 2:
            return "MOYENNE"
        else:
            return "FAIBLE"


async def test_agent_an1_standalone():
    """Test standalone Agent AN1"""
    
    print("ğŸ§ª TEST AGENT AN1 - ANALYSTE Ã‰CARTS")
    print("=" * 40)
    print("ğŸ¯ Focus: Analyse Ã©carts A1 (autoÃ©val) vs A2 (terrain)")
    print("ğŸ”¬ ModÃ¨les HSE: HFACS, Swiss Cheese, SRK, Bow-Tie")
    print("âš ï¸ Zones aveugles: Identification automatique")
    
    # DonnÃ©es A1 (autoÃ©valuations) - Scores optimistes
    print("\nğŸ“Š DONNÃ‰ES A1 (AUTOÃ‰VALUATIONS):")
    data_a1 = {
        "variables_culture_sst": {
            "usage_epi": {"score": 8.5, "source": "questionnaire", "confiance": 0.9},
            "respect_procedures": {"score": 7.8, "source": "questionnaire", "confiance": 0.8},
            "formation_securite": {"score": 7.2, "source": "questionnaire", "confiance": 0.8},
            "supervision_directe": {"score": 7.5, "source": "questionnaire", "confiance": 0.7},
            "communication_risques": {"score": 6.8, "source": "questionnaire", "confiance": 0.8},
            "leadership_sst": {"score": 7.0, "source": "questionnaire", "confiance": 0.7}
        },
        "scores_autoeval": {
            "score_global": 74,
            "fiabilite": 0.8,
            "biais_detectes": ["surconfiance", "desirabilite_sociale"]
        }
    }
    
    for var, data in data_a1["variables_culture_sst"].items():
        print(f"  â€¢ {var}: {data['score']}/10 (confiance: {data['confiance']})")
    
    # DonnÃ©es A2 (observations terrain) - RÃ©alitÃ© moins optimiste
    print("\nğŸ” DONNÃ‰ES A2 (OBSERVATIONS TERRAIN):")
    data_a2 = {
        "variables_culture_terrain": {
            "usage_epi": {"score": 4.8, "source": "observation_epi", "observations": 15},
            "respect_procedures": {"score": 5.2, "source": "procedure_compliance", "observations": 12},
            "formation_securite": {"score": 7.0, "source": "behavioral_analysis", "observations": 8},
            "supervision_directe": {"score": 3.5, "source": "hazard_detection", "observations": 10},
            "communication_risques": {"score": 5.5, "source": "behavioral_analysis", "observations": 6},
            "leadership_sst": {"score": 4.2, "source": "hazard_detection", "observations": 5}
        },
        "observations": {
            "score_comportement": 48,
            "dangers_detectes": 3,
            "epi_analyses": 15,
            "conformite_procedures": 45.0
        }
    }
    
    for var, data in data_a2["variables_culture_terrain"].items():
        print(f"  â€¢ {var}: {data['score']}/10 (observations: {data['observations']})")
    
    # Contexte
    context = {
        "secteur_scian": "CONSTRUCTION",
        "type_incident": "CHUTE_HAUTEUR", 
        "gravite": "MAJEUR"
    }
    
    print(f"\nğŸ—ï¸ CONTEXTE: {context['secteur_scian']} - {context['type_incident']}")
    
    print("\nğŸ¤– Initialisation Agent AN1...")
    agent_an1 = AN1AnalysteEcarts()
    
    print("\nğŸ”„ ANALYSE Ã‰CARTS A1 vs A2:")
    print("=" * 35)
    
    result = await agent_an1.process(data_a1, data_a2, context)
    
    if "error" in result:
        print(f"âŒ Erreur: {result['error']}")
        return
    
    # RÃ©sultats
    print(f"âœ… Score confiance: {result['agent_info']['confidence_score']:.3f}")
    print(f"ğŸ“Š Variables analysÃ©es: {len(result['ecarts_analysis']['ecarts_variables'])}")
    print(f"âš ï¸ Ã‰carts critiques: {result['ecarts_analysis']['nombre_ecarts_critiques']}")
    print(f"ğŸ”¬ ModÃ¨les HSE: {len(result['hse_models_analysis'])}")
    print(f"ğŸ’¡ Recommandations: {len(result['recommendations'])}")
    
    # Ã‰carts dÃ©taillÃ©s
    print("\nğŸ¯ Ã‰CARTS DÃ‰TECTÃ‰S PAR VARIABLE:")
    for var, ecart in result['ecarts_analysis']['ecarts_variables'].items():
        autoeval = ecart['score_autoeval']
        terrain = ecart['score_terrain']
        pct = ecart['pourcentage']
        niveau = ecart['niveau']
        direction = ecart['direction']
        
        icon = "ğŸš¨" if niveau == "critique" else "âš ï¸" if niveau == "eleve" else "ğŸ“Š"
        print(f"  {icon} {var}:")
        print(f"     AutoÃ©val: {autoeval}/10 | Terrain: {terrain}/10")
        print(f"     Ã‰cart: {pct:.1f}% ({niveau}) - {direction}")
    
    # Zones aveugles
    print("\nâš ï¸ ZONES AVEUGLES IDENTIFIÃ‰ES:")
    zones = result['ecarts_analysis']['zones_aveugles']
    if zones:
        for i, zone in enumerate(zones[:3], 1):
            print(f"  {i}. {zone['variable']} ({zone['niveau_critique'].upper()})")
            print(f"     â†’ Ã‰cart: {zone['pourcentage_ecart']:.1f}% - {zone['type_ecart']}")
            print(f"     â†’ Impact: {zone['impact_potentiel']}")
            print(f"     â†’ {zone['explication']}")
    else:
        print("  âœ… Aucune zone aveugle critique dÃ©tectÃ©e")
    
    # ModÃ¨les HSE
    print("\nğŸ”¬ ANALYSE MODÃˆLES HSE:")
    for model_code, analysis in result['hse_models_analysis'].items():
        print(f"  ğŸ¯ {analysis['model_name']}")
        print(f"     ApplicabilitÃ©: {analysis['score_applicabilite']:.0f}%")
        
        if 'interpretation' in analysis['analysis']:
            print(f"     â†’ {analysis['analysis']['interpretation']}")
        elif 'barrieres_critiques' in analysis['analysis']:
            barrieres = analysis['analysis']['barrieres_critiques']
            if barrieres:
                print(f"     â†’ BarriÃ¨res critiques: {', '.join(barrieres)}")
    
    # Recommandations
    print("\nğŸ’¡ RECOMMANDATIONS PRIORITAIRES:")
    for i, rec in enumerate(result['recommendations'][:4], 1):
        priorite = rec['priorite']
        icon = "ğŸš¨" if priorite == "URGENTE" else "âš ï¸" if priorite == "Ã‰LEVÃ‰E" else "ğŸ“‹"
        print(f"  {i}. {icon} {priorite}")
        print(f"     Action: {rec['action']}")
        if 'methode' in rec:
            print(f"     MÃ©thode: {rec['methode']}")
        if 'timeline' in rec:
            print(f"     Timeline: {rec['timeline']}")
    
    # RÃ©sumÃ©
    print("\n" + "=" * 50)
    print("ğŸ“‹ RÃ‰SUMÃ‰ ANALYSE Ã‰CARTS AN1")
    print("=" * 50)
    summary = result['summary']
    print(f"âœ… Confiance: {result['agent_info']['confidence_score']:.1%}")
    print(f"ğŸ“Š Ã‰cart moyen: {summary['ecart_moyen']:.1f}%")
    print(f"âš ï¸ Variables critiques: {summary['variables_critiques']}")
    print(f"ğŸ¯ Actions recommandÃ©es: {summary['actions_recommandees']}")
    print(f"ğŸš¨ PrioritÃ©: {summary['priorite_intervention']}")
    
    # InterprÃ©tation
    if summary['priorite_intervention'] == 'URGENTE':
        print("\nğŸš¨ ALERTE: Ã‰carts critiques - Intervention immÃ©diate requise")
        print("   â†’ Risque incident majeur si non corrigÃ© rapidement")
    elif summary['priorite_intervention'] == 'Ã‰LEVÃ‰E':
        print("\nâš ï¸ ATTENTION: Ã‰carts significatifs - Action rapide recommandÃ©e")
        print("   â†’ Planifier interventions dans les 2-4 semaines")
    else:
        print("\nâœ… SITUATION: Ã‰carts gÃ©rables - Surveillance renforcÃ©e")
        print("   â†’ Maintenir vigilance et amÃ©lioration continue")
    
    print(f"\nğŸ‰ TEST AGENT AN1 TERMINÃ‰!")
    print(f"â±ï¸ Performance: {result['agent_info']['performance_time']:.3f}s")
    print(f"ğŸ¯ Agent AN1 prÃªt pour orchestration SafetyAgentic")
    
    return result

if __name__ == "__main__":
    asyncio.run(test_agent_an1_standalone())